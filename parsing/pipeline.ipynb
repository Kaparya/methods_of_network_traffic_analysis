{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d066c343",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import re\n",
    "import sys\n",
    "from abc import ABC, abstractmethod\n",
    "from dataclasses import dataclass\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(levelname)s: %(message)s',\n",
    "    stream=sys.stdout\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ae69d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class PipelineContext:\n",
    "    \"\"\"\n",
    "    Context for processing data pipeline.\n",
    "\n",
    "    Attributes:\n",
    "        csv_path: Path to the original CSV file.\n",
    "        df: dataframe with data (default None).\n",
    "        X: features (default None).\n",
    "        y: target (default None).\n",
    "    \"\"\"\n",
    "    csv_path: Path\n",
    "    df: Optional[pd.DataFrame] = None\n",
    "    X: Optional[np.ndarray] = None\n",
    "    y: Optional[np.ndarray] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39220341",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Handler(ABC):\n",
    "    \"\"\"\n",
    "    Abstract handler for implementing a chain of responsibility.\n",
    "\n",
    "    Methods:\n",
    "        set_next(handler): Sets the next handler in the chain.\n",
    "        handle(ctx): Processes the data context and passes it to the next handler in the chain.\n",
    "        _process(ctx): Abstract method for specific processing, must be implemented in subclasses.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self._next: Optional[\"Handler\"] = None\n",
    "\n",
    "    def set_next(self, handler: \"Handler\") -> \"Handler\":\n",
    "        self._next = handler\n",
    "        return handler\n",
    "\n",
    "    def handle(self, ctx: PipelineContext) -> PipelineContext:\n",
    "        ctx = self._process(ctx)\n",
    "        if self._next:\n",
    "            return self._next.handle(ctx)\n",
    "        return ctx\n",
    "\n",
    "    @abstractmethod\n",
    "    def _process(self, ctx: PipelineContext) -> PipelineContext:\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60a76d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadCSVHandler(Handler):\n",
    "    \"\"\"\n",
    "    Handler for loading data from a CSV file.\n",
    "\n",
    "    Methods:\n",
    "        _process(ctx): Loads data from a CSV file into the context.\n",
    "    \"\"\"\n",
    "    def _process(self, ctx: PipelineContext) -> PipelineContext:\n",
    "        logging.info(f\"LoadCSVHandler: Starting to load {ctx.csv_path}\")\n",
    "        ctx.df = pd.read_csv(\n",
    "            ctx.csv_path,\n",
    "            sep=\",\",\n",
    "            quotechar='\"',\n",
    "            engine=\"python\",\n",
    "            encoding=\"utf-8\",\n",
    "            index_col=0\n",
    "        )\n",
    "        logging.info(f\"LoadCSVHandler: Loaded {ctx.csv_path} with {ctx.df.shape[0]} rows and {ctx.df.shape[1]} columns\")\n",
    "        return ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5a2cb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParseGenderAgeBirthdayHandler(Handler):\n",
    "    \"\"\"\n",
    "    Handler for parsing gender, age, and birthday information from the \"Пол, возраст\" column.\n",
    "\n",
    "    Methods:\n",
    "        _process(ctx): Extracts new columns for gender, age, and birthday month from the raw text column.\n",
    "    \"\"\"\n",
    "    def _process(self, ctx: PipelineContext) -> PipelineContext:\n",
    "        logging.info(f\"ParseGenderAgeBirthdayHandler: Starting to parse gender, age and birthday month\")\n",
    "        df = ctx.df.copy()\n",
    "        \n",
    "        # document possible gender values\n",
    "        male_values = ['Мужчина', 'Male']\n",
    "        # female_values = ['Женщина', 'Female']\n",
    "        # also encode them with 0 - male, 1 - female\n",
    "        def extract_gender(value: str) -> str:\n",
    "            raw_gender = value.split(',')[0].strip()\n",
    "            if raw_gender in male_values:\n",
    "                return 0 # Male\n",
    "            return 1 # Female\n",
    "\n",
    "        def extract_age(value: str) -> str:\n",
    "            data = value.split(',')\n",
    "            if len(data) < 2:\n",
    "                return -1\n",
    "            raw_age = data[1].strip().replace('\\xa0', ' ')\n",
    "            raw_age = raw_age.split(' ')[0]\n",
    "            return int(raw_age)\n",
    "\n",
    "        def extract_birthday_month(value: str) -> str:\n",
    "            data = value.split(',')\n",
    "            if len(data) < 3:\n",
    "                return -1\n",
    "            raw_birthday_month = data[2].strip().replace('\\xa0', ' ')\n",
    "            raw_birthday_month = raw_birthday_month.split(' ')[-2]\n",
    "            match raw_birthday_month:\n",
    "                case 'January' | 'января':\n",
    "                    return 0\n",
    "                case 'February' | 'февраля':\n",
    "                    return 1\n",
    "                case 'March' | 'марта':\n",
    "                    return 2\n",
    "                case 'April' | 'апреля':\n",
    "                    return 3\n",
    "                case 'May' | 'мая':\n",
    "                    return 4\n",
    "                case 'June' | 'июня':\n",
    "                    return 5\n",
    "                case 'July' | 'июля':\n",
    "                    return 6\n",
    "                case 'August' | 'августа':\n",
    "                    return 7\n",
    "                case 'September' | 'сентября':\n",
    "                    return 8    \n",
    "                case 'October' | 'октября':\n",
    "                    return 9\n",
    "                case 'November' | 'ноября':\n",
    "                    return 10\n",
    "                case 'December' | 'декабря':\n",
    "                    return 11\n",
    "                case _:\n",
    "                    return -1\n",
    "\n",
    "        df[\"gender\"] = df[\"Пол, возраст\"].apply(extract_gender)\n",
    "        df[\"age\"] = df[\"Пол, возраст\"].apply(extract_age)\n",
    "        df[\"birthday_month\"] = df[\"Пол, возраст\"].apply(extract_birthday_month)\n",
    "\n",
    "        df = df.drop(columns=[\"Пол, возраст\"])\n",
    "\n",
    "        ctx.df = df\n",
    "        logging.info(f\"ParseGenderAgeHandler: Parsed gender, age and birthday month\")\n",
    "        return ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27d8eb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParseSalaryHandler(Handler):\n",
    "    \"\"\"\n",
    "    Handler for parsing salary information from the \"ЗП\" column and converting it to rubles.\n",
    "\n",
    "    Methods:\n",
    "        _process(ctx): Extracts new columns for salary from the raw text column and converts it to rubles.\n",
    "    \"\"\"\n",
    "    def _process(self, ctx: PipelineContext) -> PipelineContext:\n",
    "        logging.info(f\"ParseSalaryHandler: Starting to parse salary\")\n",
    "        df = ctx.df.copy()\n",
    "\n",
    "        # approximate 2020 currency rates\n",
    "        currency_rates = {\n",
    "            'руб.': 1.0,\n",
    "            'USD': 73.35,\n",
    "            'RUB': 1.0,\n",
    "            'KZT': 0.18,\n",
    "            'бел. руб.': 2.28,\n",
    "            'EUR': 85.86,\n",
    "            'грн.': 2.72,\n",
    "            'сум': 0.005,\n",
    "            'KGS': 0.98,\n",
    "            'UAH': 2.5,\n",
    "            'BYN': 2.5,\n",
    "            'AZN': 41.1,\n",
    "            'som': 0.005,\n",
    "        }\n",
    "        \n",
    "        def extract_salary(value: str) -> str:\n",
    "            value = value.replace('\\xa0', ' ').strip().split(' ')\n",
    "            number = ''\n",
    "            currency = ''\n",
    "\n",
    "            for idx, cur in enumerate(value):\n",
    "                if cur.isdigit():\n",
    "                    number += cur\n",
    "                else:\n",
    "                    currency = ' '.join(value[idx:])\n",
    "                    break\n",
    "            return currency_rates[currency.strip()] * float(number)\n",
    "\n",
    "        df[\"salary_rub\"] = df[\"ЗП\"].apply(extract_salary)\n",
    "\n",
    "        df = df.drop(columns=[\"ЗП\"])\n",
    "\n",
    "        ctx.df = df\n",
    "        logging.info(f\"ParseSalaryHandler: Parsed salary\")\n",
    "        return ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b82e07d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParseJobHandler(Handler):\n",
    "    \"\"\"\n",
    "    Handler for parsing job information from the \"Ищет работу на должность:\" column.\n",
    "\n",
    "    Methods:\n",
    "        _process(ctx): Extracts new columns for job from the raw text column.\n",
    "    \"\"\"\n",
    "    def _process(self, ctx: PipelineContext) -> PipelineContext:\n",
    "        logging.info(f\"ParseJobHandler: Starting to parse job\")\n",
    "        df = ctx.df.copy()\n",
    "\n",
    "        # due to pie chart of the distrubution of jobs, we can see 18007 different jobs.\n",
    "        # However, there are only 133 jobs that are included more than 50 times.\n",
    "        # So let's take only them - other jobs will be called \"other\" (as they make to much noise).\n",
    "\n",
    "        # Also 133 jobs are much better for one-hot encoding (than 18007).\n",
    "        job_count = df['Ищет работу на должность:'].value_counts()[:133]\n",
    "\n",
    "        def extract_job(value: str) -> str:\n",
    "            if value in job_count:\n",
    "                return value\n",
    "            return \"other\"\n",
    "\n",
    "        df[\"job\"] = df[\"Ищет работу на должность:\"].apply(extract_job)\n",
    "\n",
    "        df = df.drop(columns=[\"Ищет работу на должность:\"])\n",
    "\n",
    "        ctx.df = df\n",
    "        logging.info(f\"ParseJobHandler: Parsed job\")\n",
    "        return ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bacbce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParseCityHandler(Handler):\n",
    "    \"\"\"\n",
    "    Handler for parsing city information from the \"Город\" column.\n",
    "\n",
    "    Methods:\n",
    "        _process(ctx): Extracts new columns for city from the raw text column.\n",
    "    \"\"\"\n",
    "    def _process(self, ctx: PipelineContext) -> PipelineContext:\n",
    "        logging.info(f\"ParseCityHandler: Starting to parse city\")\n",
    "        df = ctx.df.copy()\n",
    "\n",
    "        # group cities by regions\n",
    "        regions_map = {\n",
    "            \"Moscow & Oblast\": [\n",
    "                \"Москва\", \"Moscow\", \"Зеленоград\", \"Подольск\", \"Балашиха\", \"Химки\", \"Мытищи\", \n",
    "                \"Королев\", \"Люберцы\", \"Красногорск\", \"Одинцово\", \"Домодедово\", \"Щелково\", \n",
    "                \"Серпухов\", \"Раменское\", \"Долгопрудный\", \"Реутов\", \"Пушкино\", \"Лобня\"\n",
    "            ],\n",
    "            \"Saint Petersburg & Oblast\": [\n",
    "                \"Санкт-Петербург\", \"Saint Petersburg\", \"Гатчина\", \"Выборг\", \"Всеволожск\", \n",
    "                \"Сосновый Бор\", \"Кириши\", \"Тихвин\", \"Сертолово\"\n",
    "            ],\n",
    "            \"Central Federal District\": [\n",
    "                \"Воронеж\", \"Ярославль\", \"Рязань\", \"Тверь\", \"Тула\", \"Липецк\", \"Курск\", \n",
    "                \"Брянск\", \"Иваново\", \"Белгород\", \"Владимир\", \"Калуга\", \"Орел\", \"Смоленск\", \n",
    "                \"Тамбов\", \"Кострома\", \"Старый Оскол\"\n",
    "            ],\n",
    "            \"Volga Federal District\": [\n",
    "                \"Казань\", \"Kazan\", \"Нижний Новгород\", \"Самара\", \"Уфа\", \"Пермь\", \"Саратов\", \n",
    "                \"Тольятти\", \"Ижевск\", \"Ульяновск\", \"Оренбург\", \"Пенза\", \"Набережные Челны\", \n",
    "                \"Чебоксары\", \"Киров\", \"Саранск\", \"Стерлитамак\", \"Йошкар-Ола\"\n",
    "            ],\n",
    "            \"South and North Caucasus Federal District\": [\n",
    "                \"Краснодар\", \"Ростов-на-Дону\", \"Волгоград\", \"Сочи\", \"Ставрополь\", \"Астрахань\", \n",
    "                \"Севастополь\", \"Симферополь\", \"Новороссийск\", \"Таганрог\", \"Махачкала\", \n",
    "                \"Владикавказ\", \"Грозный\", \"Майкоп\", \"Пятигорск\"\n",
    "            ],\n",
    "            \"Ural Federal District\": [\n",
    "                \"Екатеринбург\", \"Yekaterinburg\", \"Челябинск\", \"Тюмень\", \"Магнитогорск\", \n",
    "                \"Сургут\", \"Нижневартовск\", \"Курган\", \"Новый Уренгой\", \"Ноябрьск\", \"Ханты-Мансийск\"\n",
    "            ],\n",
    "            \"Siberian Federal District\": [\n",
    "                \"Новосибирск\", \"Novosibirsk\", \"Красноярск\", \"Омск\", \"Томск\", \"Барнаул\", \n",
    "                \"Иркутск\", \"Кемерово\", \"Новокузнецк\", \"Абакан\", \"Братск\", \"Ангарск\"\n",
    "            ],\n",
    "            \"Far Eastern Federal District\": [\n",
    "                \"Владивосток\", \"Хабаровск\", \"Улан-Удэ\", \"Чита\", \"Благовещенск\", \"Якутск\", \n",
    "                \"Петропавловск-Камчатский\", \"Южно-Сахалинск\", \"Находка\"\n",
    "            ],\n",
    "            \"Kazakhstan\": [\n",
    "                \"Алматы\", \"Almaty\", \"Нур-Султан\", \"Астана\", \"Astana\", \"Шымкент\", \"Актобе\", \n",
    "                \"Караганда\", \"Атырау\", \"Актау\", \"Павлодар\", \"Уральск\"\n",
    "            ],\n",
    "            \"Belarus\": [\n",
    "                \"Минск\", \"Minsk\", \"Гомель\", \"Витебск\", \"Могилев\", \"Гродно\", \"Брест\"\n",
    "            ],\n",
    "            \"Other countries / CIS\": [\n",
    "                \"Киев\", \"Kyiv\", \"Ташкент\", \"Бишкек\", \"Тбилиси\", \"Баку\", \"Ереван\", \"Рига\", \"Вильнюс\"\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        def extract_city(value: str) -> str:\n",
    "            city_name = value.split(',')[0].strip()\n",
    "            for region, cities in regions_map.items():\n",
    "                if city_name in cities:\n",
    "                    return region\n",
    "            return \"Other\"\n",
    "\n",
    "        df[\"city\"] = df[\"Город\"].apply(extract_city)\n",
    "\n",
    "        df = df.drop(columns=[\"Город\"])\n",
    "\n",
    "        ctx.df = df\n",
    "        logging.info(f\"ParseCityHandler: Parsed city\")\n",
    "        return ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "164df716",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParseEmploymentHandler(Handler):\n",
    "    \"\"\"\n",
    "    Handler for parsing employment information from the \"Занятость\" column.\n",
    "\n",
    "    Methods:\n",
    "        _process(ctx): Extracts new columns for employment from the raw text column.\n",
    "    \"\"\"\n",
    "    def _process(self, ctx: PipelineContext) -> PipelineContext:\n",
    "        logging.info(f\"ParseEmploymentHandler: Starting to parse employment\")\n",
    "        df = ctx.df.copy()\n",
    "\n",
    "        # group employment\n",
    "        employment_map = {\n",
    "            \"full_time\": [\"полная занятость\", \"full time\"],\n",
    "            \"part_time\": [\"частичная занятость\", \"part time\"],\n",
    "            \"project\": [\"проектная работа\", \"project work\"],\n",
    "            \"internship\": [\"стажировка\", \"work placement\"],\n",
    "            \"volunteering\": [\"волонтерство\", \"volunteering\"]\n",
    "        }\n",
    "\n",
    "        for column_name, keywords in employment_map.items():\n",
    "            def check_employment(value: str) -> int:\n",
    "                value_lower = value.lower()\n",
    "                if any(keyword in value_lower for keyword in keywords):\n",
    "                    return 1\n",
    "                return 0\n",
    "            \n",
    "            df[f\"emp_{column_name}\"] = df[\"Занятость\"].apply(check_employment)\n",
    "\n",
    "        df = df.drop(columns=[\"Занятость\"])\n",
    "\n",
    "        ctx.df = df\n",
    "        logging.info(f\"ParseEmploymentHandler: Parsed employment\")\n",
    "        return ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beca9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParseWorkScheduleHandler(Handler):\n",
    "    \"\"\"\n",
    "    Handler for parsing work schedule information from the \"График\" column.\n",
    "\n",
    "    Methods:\n",
    "        _process(ctx): Extracts new columns for work schedule from the raw text column.\n",
    "    \"\"\"\n",
    "    def _process(self, ctx: PipelineContext) -> PipelineContext:\n",
    "        logging.info(f\"ParseWorkScheduleHandler: Starting to parse work schedule\")\n",
    "        df = ctx.df.copy()\n",
    "\n",
    "        schedule_map = {\n",
    "            \"full_day\": [\"полный день\", \"full day\"],\n",
    "            \"flexible\": [\"гибкий график\", \"flexible schedule\"],\n",
    "            \"shift\": [\"сменный график\", \"shift schedule\"],\n",
    "            \"remote\": [\"удаленная работа\", \"remote working\"],\n",
    "            \"rotation\": [\"вахтовый метод\", \"rotation based work\"]\n",
    "        }\n",
    "\n",
    "        for column_name, keywords in schedule_map.items():\n",
    "            def check_schedule(value: str) -> int:\n",
    "                value_lower = value.lower()\n",
    "                if any(keyword in value_lower for keyword in keywords):\n",
    "                    return 1\n",
    "                return 0\n",
    "            \n",
    "            df[f\"sch_{column_name}\"] = df[\"График\"].apply(check_schedule)\n",
    "\n",
    "        df = df.drop(columns=[\"График\"])\n",
    "\n",
    "        ctx.df = df\n",
    "        logging.info(f\"ParseWorkScheduleHandler: Parsed work schedule\")\n",
    "        return ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d8df93d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParseExperienceHandler(Handler):\n",
    "    \"\"\"\n",
    "    Handler for parsing experience information from the \"Опыт (двойное нажатие для полной версии)\" column.\n",
    "\n",
    "    Methods:\n",
    "        _process(ctx): Extracts new columns for experience from the raw text column.\n",
    "    \"\"\"\n",
    "    def _process(self, ctx: PipelineContext) -> PipelineContext:\n",
    "        logging.info(f\"ParseExperienceHandler: Starting to parse experience\")\n",
    "        df = ctx.df.copy()\n",
    "\n",
    "        def check_experience(value: str) -> int:\n",
    "            years_pattern = r'(\\d+)\\s*(?:год|года|лет)'\n",
    "            months_pattern = r'(\\d+)\\s*(?:месяц|месяца|месяцев)'\n",
    "            \n",
    "            experience_part = value.split('\\n')[0]\n",
    "            \n",
    "            years = re.search(years_pattern, experience_part)\n",
    "            months = re.search(months_pattern, experience_part)\n",
    "            total_months = 0\n",
    "            if years:\n",
    "                total_months += int(years.group(1)) * 12\n",
    "            if months:\n",
    "                total_months += int(months.group(1))\n",
    "                \n",
    "            return total_months\n",
    "        \n",
    "        df[\"experience_months\"] = df[\"Опыт (двойное нажатие для полной версии)\"].apply(check_experience)\n",
    "\n",
    "        df = df.drop(columns=[\"Опыт (двойное нажатие для полной версии)\"])\n",
    "\n",
    "        ctx.df = df\n",
    "        logging.info(f\"ParseExperienceHandler: Parsed experience\")\n",
    "        return ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "174c1253",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParseLastPlaceHandler(Handler):\n",
    "    \"\"\"\n",
    "    Handler for parsing last place information from the \"Последенее/нынешнее место работы\" column.\n",
    "\n",
    "    Methods:\n",
    "        _process(ctx): Removes column for last place from the dataframe.\n",
    "    \"\"\"\n",
    "    def _process(self, ctx: PipelineContext) -> PipelineContext:\n",
    "        logging.info(f\"ParseLastPlaceHandler: Starting to parse last place\")\n",
    "        df = ctx.df.copy()\n",
    "\n",
    "        df = df.drop(columns=[\"Последенее/нынешнее место работы\"])\n",
    "\n",
    "        ctx.df = df\n",
    "        logging.info(f\"ParseLastPlaceHandler: Parsed last place\")\n",
    "        return ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6d958aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParseLastJobHandler(Handler):\n",
    "    \"\"\"\n",
    "    Handler for parsing last job information from the \"Последеняя/нынешняя должность\" column.\n",
    "\n",
    "    Methods:\n",
    "        _process(ctx): Extracts new columns for last job from the raw text column.\n",
    "    \"\"\"\n",
    "    def _process(self, ctx: PipelineContext) -> PipelineContext:\n",
    "        logging.info(f\"ParseLastJobHandler: Starting to parse last job\")\n",
    "        df = ctx.df.copy()\n",
    "\n",
    "        # lets take jobs from jobs column and parse only them\n",
    "        jobs = df['job'].value_counts()\n",
    "\n",
    "        def extract_job(value: str) -> str:\n",
    "            if value in jobs:\n",
    "                return value\n",
    "            return \"other\"\n",
    "\n",
    "        df[\"last_job\"] = df[\"Последеняя/нынешняя должность\"].apply(extract_job)\n",
    "\n",
    "        df = df.drop(columns=[\"Последеняя/нынешняя должность\"])\n",
    "\n",
    "        ctx.df = df\n",
    "        logging.info(f\"ParseLastJobHandler: Parsed last job\")\n",
    "        return ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2304769b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParseEducationHandler(Handler):\n",
    "    \"\"\"\n",
    "    Handler for parsing education information from the \"Образование и ВУЗ\" column.\n",
    "\n",
    "    Methods:\n",
    "        _process(ctx): Extracts new columns for education from the raw text column.\n",
    "    \"\"\"\n",
    "    def _process(self, ctx: PipelineContext) -> PipelineContext:\n",
    "        logging.info(f\"ParseEducationHandler: Starting to parse education\")\n",
    "        df = ctx.df.copy()\n",
    "\n",
    "        education_map = {\n",
    "            \"incomplete_higher\": [\"неоконченное высшее\", \"incomplete higher\"],\n",
    "            \"higher\": [\"высшее образование\", \"higher education\"],\n",
    "            \"secondary_special\": [\"среднее специальное\", \"secondary special\"],\n",
    "            \"secondary\": [\"среднее образование\", \"secondary education\"]\n",
    "        }\n",
    "\n",
    "        for column_name, keywords in education_map.items():\n",
    "            def extract_level(value: str) -> int:\n",
    "                value_lower = value.lower()\n",
    "                if any(keyword in value_lower for keyword in keywords):\n",
    "                    return 1\n",
    "                return 0\n",
    "            \n",
    "            df[f\"edu_{column_name}\"] = df[\"Образование и ВУЗ\"].apply(extract_level)\n",
    "\n",
    "        df = df.drop(columns=[\"Образование и ВУЗ\"])\n",
    "\n",
    "        ctx.df = df\n",
    "        logging.info(f\"ParseEducationHandler: Parsed education\")\n",
    "        return ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3cd38fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParseResumeHandler(Handler):\n",
    "    \"\"\"\n",
    "    Handler for parsing resume information from the \"Обновление резюме\" column. \n",
    "    Splits resume in \"old\" (more than 1 year) and \"not old\" (less than 1 year).\n",
    "\n",
    "    Methods:\n",
    "        _process(ctx): Extracts new columns for resume from the raw text column.\n",
    "    \"\"\"\n",
    "    def _process(self, ctx: PipelineContext) -> PipelineContext:\n",
    "        logging.info(f\"ParseResumeHandler: Starting to parse resume\")\n",
    "        df = ctx.df.copy()\n",
    "\n",
    "        def extract_oldness(value: str) -> str:\n",
    "            try:\n",
    "                year = int(value.split('.')[2].split(' ')[0])\n",
    "            except Exception as e:\n",
    "                logging.error(f\"ParseResumeHandler: Error extracting oldness: {e}\")\n",
    "                year = 0\n",
    "            return 0 if year > 2018 else 1\n",
    "\n",
    "        df[\"old_resume\"] = df[\"Обновление резюме\"].apply(extract_oldness)\n",
    "\n",
    "        df = df.drop(columns=[\"Обновление резюме\"])\n",
    "\n",
    "        ctx.df = df\n",
    "        logging.info(f\"ParseResumeHandler: Parsed resume\")\n",
    "        return ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f7add381",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParseAutoHandler(Handler):\n",
    "    \"\"\"\n",
    "    Handler for parsing auto information from the \"Авто\" column. \n",
    "\n",
    "    Methods:\n",
    "        _process(ctx): Extracts new columns for auto from the raw text column.\n",
    "    \"\"\"\n",
    "    def _process(self, ctx: PipelineContext) -> PipelineContext:\n",
    "        logging.info(f\"ParseAutoHandler: Starting to parse auto\")\n",
    "        df = ctx.df.copy()\n",
    "\n",
    "        def extract_auto(value: str) -> str:\n",
    "            match value:\n",
    "                case 'Имеется собственный автомобиль':\n",
    "                    return 1\n",
    "                case 'Не указано':\n",
    "                    return 0\n",
    "                case _:\n",
    "                    return 0\n",
    "\n",
    "        df[\"auto\"] = df[\"Авто\"].apply(extract_auto)\n",
    "\n",
    "        df = df.drop(columns=[\"Авто\"])\n",
    "\n",
    "        ctx.df = df\n",
    "        logging.info(f\"ParseAutoHandler: Parsed auto\")\n",
    "        return ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "571a9e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncodeCategoricalFeaturesHandler(Handler):\n",
    "    \"\"\"\n",
    "    Handler for encoding categorical features. \n",
    "\n",
    "    Methods:\n",
    "        _process(ctx): Encodes categorical features.\n",
    "    \"\"\"\n",
    "    def _process(self, ctx: PipelineContext) -> PipelineContext:\n",
    "        logging.info(f\"EncodeCategoricalFeaturesHandler: Start with {ctx.df.shape[1]} features\")\n",
    "        df = ctx.df.copy()\n",
    "\n",
    "        cat_cols = df.select_dtypes(include=\"object\").columns\n",
    "        df = pd.get_dummies(df, columns=cat_cols, drop_first=True)\n",
    "\n",
    "        ctx.df = df\n",
    "        logging.info(f\"EncodeCategoricalFeaturesHandler: Updated df with {ctx.df.shape[1]} features\")\n",
    "        return ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "26dcc9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitDataHandler(Handler):\n",
    "    \"\"\"\n",
    "    Handler for splitting the dataset into features and target.\n",
    "\n",
    "    Methods:\n",
    "        _process(ctx): Splits the dataset into features and target.\n",
    "    \"\"\"\n",
    "    def _process(self, ctx: PipelineContext) -> PipelineContext:\n",
    "        logging.info(f\"SplitDataHandler: Splitting data into features and target\")\n",
    "        df = ctx.df.copy()\n",
    "\n",
    "        ctx.X = df.drop(columns=[\"salary_rub\"])\n",
    "        ctx.y = df[\"salary_rub\"]\n",
    "\n",
    "        ctx.df = None\n",
    "        logging.info(f\"SplitDataHandler: df was split into X and y.\")\n",
    "        return ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fd6396ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveDataHandler(Handler):\n",
    "    \"\"\"\n",
    "    Handler for saving the dataset into X.npy and y.npy files.\n",
    "\n",
    "    Methods:\n",
    "        _process(ctx): Saves the dataset into X.npy and y.npy files.\n",
    "    \"\"\"\n",
    "    def _process(self, ctx: PipelineContext) -> PipelineContext:\n",
    "        logging.info(f\"SaveDataHandler: Saving data\")\n",
    "        np.save(\"X.npy\", ctx.X)\n",
    "        np.save(\"y.npy\", ctx.y)\n",
    "        logging.info(f\"SaveDataHandler: Data was saved to X.npy and y.npy files\")\n",
    "        return ctx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b131cbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: LoadCSVHandler: Starting to load hh.csv\n",
      "INFO: LoadCSVHandler: Loaded hh.csv with 66945 rows and 12 columns\n",
      "INFO: ParseGenderAgeBirthdayHandler: Starting to parse gender, age and birthday month\n",
      "INFO: ParseGenderAgeHandler: Parsed gender, age and birthday month\n",
      "INFO: ParseSalaryHandler: Starting to parse salary\n",
      "INFO: ParseSalaryHandler: Parsed salary\n",
      "INFO: ParseJobHandler: Starting to parse job\n",
      "INFO: ParseJobHandler: Parsed job\n",
      "INFO: ParseCityHandler: Starting to parse city\n",
      "INFO: ParseCityHandler: Parsed city\n",
      "INFO: ParseEmploymentHandler: Starting to parse employment\n",
      "INFO: ParseEmploymentHandler: Parsed employment\n",
      "INFO: ParseWorkScheduleHandler: Starting to parse work schedule\n",
      "INFO: ParseWorkScheduleHandler: Parsed work schedule\n",
      "INFO: ParseExperienceHandler: Starting to parse experience\n",
      "INFO: ParseExperienceHandler: Parsed experience\n",
      "INFO: ParseLastPlaceHandler: Starting to parse last place\n",
      "INFO: ParseLastPlaceHandler: Parsed last place\n",
      "INFO: ParseLastJobHandler: Starting to parse last job\n",
      "INFO: ParseLastJobHandler: Parsed last job\n",
      "INFO: ParseEducationHandler: Starting to parse education\n",
      "INFO: ParseEducationHandler: Parsed education\n",
      "INFO: ParseResumeHandler: Starting to parse resume\n",
      "ERROR: ParseResumeHandler: Error extracting oldness: list index out of range\n",
      "INFO: ParseResumeHandler: Parsed resume\n",
      "INFO: ParseAutoHandler: Starting to parse auto\n",
      "INFO: ParseAutoHandler: Parsed auto\n",
      "INFO: EncodeCategoricalFeaturesHandler: Start with 24 features\n",
      "INFO: EncodeCategoricalFeaturesHandler: Updated df with 298 features\n",
      "INFO: SplitDataHandler: Splitting data into features and target\n",
      "INFO: SplitDataHandler: df was split into X and y.\n",
      "INFO: SaveDataHandler: Saving data\n",
      "INFO: SaveDataHandler: Data was saved to X.npy and y.npy files\n"
     ]
    }
   ],
   "source": [
    "def build_pipeline() -> Handler:\n",
    "    \"\"\"\n",
    "    Builds the full data processing pipeline by chaining together all handlers in the required order.\n",
    "\n",
    "    Returns:\n",
    "        Handler: The first handler in the pipeline (LoadCSVHandler).\n",
    "    \"\"\"\n",
    "    load = LoadCSVHandler()\n",
    "    gender_age = ParseGenderAgeBirthdayHandler()\n",
    "    salary = ParseSalaryHandler()\n",
    "    job = ParseJobHandler()\n",
    "    city = ParseCityHandler()\n",
    "    employment = ParseEmploymentHandler()\n",
    "    work_schedule = ParseWorkScheduleHandler()\n",
    "    experience = ParseExperienceHandler()\n",
    "    last_place = ParseLastPlaceHandler()\n",
    "    last_job = ParseLastJobHandler()\n",
    "    education = ParseEducationHandler()\n",
    "    resume = ParseResumeHandler()\n",
    "    auto = ParseAutoHandler()\n",
    "    encode_categorical_features = EncodeCategoricalFeaturesHandler()\n",
    "\n",
    "    split_data = SplitDataHandler()\n",
    "\n",
    "    save_data = SaveDataHandler()\n",
    "\n",
    "    load.set_next(gender_age)\\\n",
    "        .set_next(salary)\\\n",
    "        .set_next(job)\\\n",
    "        .set_next(city)\\\n",
    "        .set_next(employment)\\\n",
    "        .set_next(work_schedule)\\\n",
    "        .set_next(experience)\\\n",
    "        .set_next(last_place)\\\n",
    "        .set_next(last_job)\\\n",
    "        .set_next(education)\\\n",
    "        .set_next(resume)\\\n",
    "        .set_next(auto)\\\n",
    "        .set_next(encode_categorical_features)\\\n",
    "        .set_next(split_data)\\\n",
    "        .set_next(save_data)\n",
    "    \n",
    "    return load\n",
    "\n",
    "pipeline = build_pipeline()\n",
    "\n",
    "ctx = PipelineContext(csv_path=Path(\"hh.csv\"))\n",
    "ctx = pipeline.handle(ctx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
